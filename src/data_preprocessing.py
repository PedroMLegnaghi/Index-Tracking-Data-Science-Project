"""
M√≥dulo de Pr√©-processamento de Dados
======================================

Este m√≥dulo √© respons√°vel pela limpeza e prepara√ß√£o dos dados coletados para Index Tracking,
incluindo tratamento de valores faltantes e c√°lculo de retornos.

‚ö†Ô∏è DECIS√ÉO DE DESIGN - OUTLIERS:
==================================
Outliers N√ÉO s√£o tratados por padr√£o neste projeto!

JUSTIFICATIVA:
- Objetivo: Replicar o √≠ndice, inclusive em eventos extremos (crashes, rallies)
- Outliers s√£o REAIS (COVID-19 -30%, Crise 2008 -20%, Black Monday -22%)
- Se o √≠ndice cai 20%, a carteira DEVE cair ~20% (baixo tracking error)
- Tratar outliers artificialmente reduz TE no treino mas piora out-of-sample
- Retornos logar√≠tmicos j√° limitam naturalmente valores extremos
- Backtesting precisa testar robustez em per√≠odos vol√°teis

Para outros projetos (previs√£o, classifica√ß√£o), as fun√ß√µes de detec√ß√£o/tratamento
de outliers est√£o dispon√≠veis mas comentadas no pipeline.

Funcionalidades:
    - Tratamento de valores faltantes (missing data)
    - Detec√ß√£o de outliers (dispon√≠vel, mas n√£o usada por padr√£o)
    - Tratamento de outliers (dispon√≠vel, mas n√£o usada por padr√£o)
    - C√°lculo de retornos logar√≠tmicos e simples
    - Alinhamento temporal entre √≠ndice e a√ß√µes
    - Remo√ß√£o de ativos com dados insuficientes

Autor: Projeto Final - Bootcamp Data Science
Data: Outubro 2025
"""

import pandas as pd
import numpy as np
from typing import Tuple, List, Optional
import warnings
warnings.filterwarnings('ignore')


class DataPreprocessor:
    """
    Classe para pr√©-processar dados de mercado financeiro.
    
    Attributes:
        max_missing_pct (float): Percentual m√°ximo permitido de dados faltantes (0-1)
        max_consecutive_missing (int): N√∫mero m√°ximo de dias consecutivos faltantes
    """
    
    def __init__(self, 
                 max_missing_pct: float = 0.1,
                 max_consecutive_missing: int = 30,):
        """
        Inicializa o pr√©-processador.
        
        Args:
            max_missing_pct: Percentual m√°ximo de dados faltantes (padr√£o: 10%)
            max_consecutive_missing: M√°ximo de dias consecutivos faltantes (padr√£o: 30)
        """
        self.max_missing_pct = max_missing_pct
        self.max_consecutive_missing = max_consecutive_missing
        
        print(f"‚úì DataPreprocessor inicializado:")
        print(f"  - Max missing: {max_missing_pct*100:.1f}%")
        print(f"  - Max consecutive missing: {max_consecutive_missing} dias")
    
    def check_missing_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        Analisa dados faltantes no DataFrame.
        
        Args:
            data: DataFrame com dados a serem analisados
            
        Returns:
            DataFrame com estat√≠sticas de dados faltantes por coluna
        """

        # fazer c√≥pia do dataframe dado em um outro dataframe
        missing_stats = pd.DataFrame({
            'Total_Missing': data.isnull().sum(),
            'Pct_Missing': (data.isnull().sum() / len(data) * 100).round(2),
            # Retorna o indice do primeiro e √∫ltimo valor n√£o nulo
            # importante para saber se o dado est√° faltando no in√≠cio ou fim da s√©rie temporal que colocamos, ou seja, importante para definirmos 
            # o per√≠odo de escolha do ativo
            'First_Valid': data.apply(lambda x: x.first_valid_index()),
            'Last_Valid': data.apply(lambda x: x.last_valid_index())
        })
        
        # Filtrar apenas colunas com dados faltantes e ordenar por percentual de dados faltantes
        missing_stats = missing_stats[missing_stats['Total_Missing'] > 0].sort_values(
            'Pct_Missing', ascending=False
        )
        
        if len(missing_stats) > 0:
            print(f"\n‚ö† Dados faltantes encontrados em {len(missing_stats)} colunas:")
            print(missing_stats.head(10))
        else:
            print("\n‚úì Nenhum dado faltante encontrado")
        
        return missing_stats
    
    def check_consecutive_missing(self, series: pd.Series) -> int:
        """
        Verifica o n√∫mero m√°ximo de valores consecutivos faltantes em uma s√©rie.
        Usada na fun√ß√£o de remo√ß√£o de colunas com muitos dados faltantes. (remove_high_missing_columns)
        
        Args:
            series: S√©rie temporal a ser analisada, ex: data['AAPL']
            
        Returns:
            N√∫mero m√°ximo de valores consecutivos faltantes na s√©rie/coluna dada
        """
        # Criar s√©rie bin√°ria (1 = faltante, 0 = presente)
        is_null = series.isnull().astype(int)
        
        # Agrupar valores consecutivos
        groups = (is_null != is_null.shift()).cumsum()
        
        # Contar m√°ximo de 1s consecutivos
        max_consecutive = is_null.groupby(groups).sum().max()
        
        return int(max_consecutive) if not np.isnan(max_consecutive) else 0
    
    def remove_high_missing_columns(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        Remove colunas com muitos dados faltantes.
        
        Args:
            data: DataFrame original
            
        Returns:
            DataFrame filtrado
        """
        print(f"\nüîç Analisando colunas com dados faltantes...")

        # Guardar o n√∫mero inicial de colunas para comparar no final com a quantidade de colunas removidas
        initial_cols = len(data.columns)
        
        # Calcular percentual de missing
        missing_pct = data.isnull().sum() / len(data)
        
        # Colunas a remover = percentual de missing > limite posto no objeto de data_preprocessor
        cols_to_remove_due_to_general_missing_data = missing_pct[missing_pct > self.max_missing_pct].index.tolist()
        
        # Verificar missing consecutivos, adicionando √† lista de colunas para remover do dataset as
        # colunas que ultrapassem o limite de dias consecutivos com dados faltantes
        cols_to_remove_due_to_consecutive_days_missing_data = []
        for col in data.columns:
            max_consecutive = self.check_consecutive_missing(data[col])
            if max_consecutive > self.max_consecutive_missing:
                cols_to_remove_due_to_consecutive_days_missing_data.append(col)
        
        # Unir ambas as listas
        all_cols_to_remove = list(set(cols_to_remove_due_to_general_missing_data + cols_to_remove_due_to_consecutive_days_missing_data))
        
        # Remover colunas problem√°ticas
        data_clean = data.drop(columns=all_cols_to_remove)
        
        print(f"‚úì Colunas removidas: {len(all_cols_to_remove)}")
        print(f"  - Por % missing: {len(cols_to_remove_due_to_general_missing_data)}")
        print(f"  - Por missing consecutivo: {len(cols_to_remove_due_to_consecutive_days_missing_data)}")
        print(f"  Colunas restantes: {len(data_clean.columns)} de {initial_cols}")
        
        if len(all_cols_to_remove) > 0 and len(all_cols_to_remove) <= 20:
            print(f"  Removidas: {', '.join(all_cols_to_remove)}")
        
        return data_clean
    
    def interpolate_missing_values(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        Interpola valores faltantes restantes usando interpola√ß√£o linear.
        O m√©todo de interpola√ß√£o √© o seguinte:
        - Interpola√ß√£o linear para valores internos
        - Forward fill e backward fill para bordas
        Utilizado ap√≥s remo√ß√£o de colunas com muitos dados faltantes.
        
        Args:
            data: DataFrame com alguns valores faltantes
            
        Returns:
            DataFrame com valores interpolados (sem valores faltantes)
        """
        print(f"\nüîß Interpolando valores faltantes...")
        
        missing_before = data.isnull().sum().sum()
        
        # Interpola√ß√£o linear: 
        # a interpola√ß√£o linear √© um m√©todo que estima os valores faltantes com base nos valores conhecidos adjacentes.
        # Por exemplo, se temos os valores [1, NaN, 3], a interpola√ß√£o linear preencher√° o NaN com 2, que √© a m√©dia dos valores 1 e 3.
        # limit_direction='both' garante que a interpola√ß√£o seja feita em ambas as dire√ß√µes (in√≠cio e fim da s√©rie)
        # Exemplo: Pre√ßos da AAPL: [150, NaN, NaN, 153] -> [150, 151, 152, 153]
        data_interpolated = data.interpolate(method='linear', limit_direction='both')
        
        # Forward fill e backward fill para bordas
        # Depois da interpola√ß√£o linear, ainda podem restar valores NaN nas bordas (in√≠cio ou fim da s√©rie).
        # O forward fill (ffill) preenche valores NaN da cauda com o √∫ltimo valor conhecido
        # O backward fill (bfill) preenche valores NaN da cabe√ßa com o pr√≥ximo valor conhecido
        # Exemplo: Pre√ßos da AAPL: [NaN, NaN, 150, 151, NaN, Nan] 
        # -Depois do ffill-> [NaN, NaN, 150, 151, 151, 151]
        # -Depois do bfill-> [150, 150, 150, 151, 151, 151]
        data_interpolated:pd.DataFrame = data_interpolated.fillna(method='ffill')
        data_interpolated:pd.DataFrame = data_interpolated.fillna(method='bfill')
        
        missing_after = data_interpolated.isnull().sum().sum()
        
        print(f"‚úì Interpola√ß√£o completa:")
        print(f"  - Missing antes: {missing_before}")
        print(f"  - Missing depois: {missing_after}")
        
        return data_interpolated
    
    
    def calculate_returns(self, prices: pd.DataFrame, method: str = 'log') -> pd.DataFrame:
        """
        Calcula retornos a partir de pre√ßos.
        
        Args:
            prices: DataFrame com pre√ßos
            method: Tipo de retorno ('log' ou 'simple')
            
        Returns:
            DataFrame com retornos calculados
        """
        print(f"\nüìä Calculando retornos ({method})...")
        
        if method == 'log':
            # Retornos logar√≠tmicos: ln(P_t / P_{t-1})
            returns = np.log(prices / prices.shift(1))
        elif method == 'simple':
            # Retornos simples: (P_t - P_{t-1}) / P_{t-1}
            returns = prices.pct_change()
        else:
            raise ValueError("method deve ser 'log' ou 'simple'")
        
        # Remover primeira linha (NaN)
        returns = returns.dropna()
        
        
        return returns
    
    def align_data(self, index_data: pd.DataFrame, stocks_data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        Sincroniza temporalmente os dados do √≠ndice e das a√ß√µes, garantindo que ambos tenham exatamente as mesmas datas.
        Cr√≠tico para Index Tracking, garantido a consist√™ncia dos dados (sem missing values na hora de comparar dados de mesmo dias)
        Args:
            index_data: DataFrame do √≠ndice
            stocks_data: DataFrame das a√ß√µes
            
        Returns:
            Tupla (index_aligned, stocks_aligned)
        """
        print(f"\nüîó Alinhando dados temporalmente...")
        
        # Obter datas em comum
        common_dates = index_data.index.intersection(stocks_data.index)
        
        # Filtrar ambos DataFrames
        index_aligned = index_data.loc[common_dates]
        stocks_aligned = stocks_data.loc[common_dates]
        
        print(f"‚úì Alinhamento conclu√≠do:")
        print(f"  Datas do √≠ndice: {len(index_data)}")
        print(f"  Datas das a√ß√µes: {len(stocks_data)}")
        print(f"  Datas em comum: {len(common_dates)}")
        print(f"  Per√≠odo: {common_dates[0].strftime('%Y-%m-%d')} at√© {common_dates[-1].strftime('%Y-%m-%d')}")
        
        return index_aligned, stocks_aligned
    
    def preprocess_pipeline(self, index_data: pd.DataFrame, stocks_data: pd.DataFrame,
                          calculate_ret: bool = True) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        Pipeline completo de pr√©-processamento para Index Tracking.
        Transforma dados brutos ‚Üí dados prontos para otimiza√ß√£o

        Args:
            index_data: DataFrame do √≠ndice (OHLCV)
            stocks_data: DataFrame das a√ß√µes (pre√ßos ajustados)
            calculate_ret: Se True, calcula retornos logar√≠tmicos ao final (padr√£o: True)
            
        Returns:
            Tupla (index_processed, stocks_processed)
            - Se calculate_ret=True: retorna retornos logar√≠tmicos
            - Se calculate_ret=False: retorna pre√ßos limpos
        """
        print(f"\n{'='*70}")
        print("INICIANDO PIPELINE DE PR√â-PROCESSAMENTO")
        print(f"{'='*70}")
        
        # 1. Alinhar temporalmente
        index_aligned, stocks_aligned = self.align_data(index_data, stocks_data)
        
        # 2. Analisar dados faltantes
        print(f"\n--- AN√ÅLISE DO √çNDICE ---")
        self.check_missing_data(index_aligned)
        
        print(f"\n--- AN√ÅLISE DAS A√á√ïES ---")
        self.check_missing_data(stocks_aligned)
        
        # 3. Remover colunas com muitos missing
        stocks_clean = self.remove_high_missing_columns(stocks_aligned)
        
        # 4. Interpolar valores faltantes restantes
        index_clean = self.interpolate_missing_values(index_aligned[['Close']])
        stocks_clean = self.interpolate_missing_values(stocks_clean)
        
        # 5. Detectar e tratar outliers (DESABILITADO por padr√£o para Index Tracking)
        # 
        # JUSTIFICATIVA:
        # - Objetivo: Replicar o √≠ndice (inclusive em eventos extremos como crashes)
        # - Outliers s√£o REAIS (COVID-19, crises financeiras, etc.)
        # - Se o √≠ndice caiu 20%, a carteira DEVE cair ~20% (baixo tracking error)
        # - Tratar outliers artificialmente reduz TE no treino, mas piora out-of-sample
        # - Retornos logar√≠tmicos j√° limitam naturalmente valores extremos
        #
        
        # 6. Calcular retornos
        if calculate_ret:
            index_returns = self.calculate_returns(index_clean, method='log')
            stocks_returns = self.calculate_returns(stocks_clean, method='log')
            
            # Uma vez que o "calculate_returns" acaba fazendo com que a primeira linha do dataset se torne NaN (pois
            # a primeira linha n√£o tem como ter um par√¢metro de aumento ou descr√©scimo percentual em rela√ß√£o a ningu√©m, ou seja
            # ,pois a primeira linha √© o referencial), fazemos a exclus√£o da primeira linha em ambos √≠ndice e array das a√ß√µes
            index_returns = index_returns.iloc[1:]
            stocks_returns = stocks_returns.iloc[1:]
            
            print(f"\n{'='*70}")
            print("PR√â-PROCESSAMENTO FINALIZADO - RETORNOS CALCULADOS")
            print(f"{'='*70}")
            print(f"  √çndice: {index_returns.shape}")
            print(f"  A√ß√µes: {stocks_returns.shape}")
            print(f"{'='*70}\n")
            
            return index_returns, stocks_returns
        
        else:
            print(f"\n{'='*70}")
            print("PR√â-PROCESSAMENTO FINALIZADO - PRE√áOS LIMPOS")
            print(f"{'='*70}")
            print(f"  √çndice: {index_clean.shape}")
            print(f"  A√ß√µes: {stocks_clean.shape}")
            print(f"{'='*70}\n")
            
            return index_clean, stocks_clean


